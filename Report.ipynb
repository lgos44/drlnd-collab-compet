{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaboration and Competition\n",
    "\n",
    "The objective of this project is to train agents to play tennis in the Unity ML-Agents Tennis environment.\n",
    "\n",
    "## 1. Starting the Environment\n",
    "We begin by importing the necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "from config import Config\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Tennis.app\"`\n",
    "- **Windows** (x86): `\"path/to/Tennis_Windows_x86/Tennis.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Tennis_Windows_x86_64/Tennis.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Tennis_Linux/Tennis.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Tennis_Linux/Tennis.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Tennis_Linux_NoVis/Tennis.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Tennis_Linux_NoVis/Tennis.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Tennis.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Tennis.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=config.environment_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Examining the State and Action Spaces\n",
    "\n",
    "In this environment, two agents control rackets to bounce a ball over a net. If an agent hits the ball over the net, it receives a reward of +0.1.  If an agent lets a ball hit the ground or hits the ball out of bounds, it receives a reward of -0.01.  Thus, the goal of each agent is to keep the ball in play.\n",
    "\n",
    "The observation space consists of 8 variables corresponding to the position and velocity of the ball and racket. Two continuous actions are available, corresponding to movement toward (or away from) the net, and jumping. \n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 2\n",
      "Size of each action: 2\n",
      "There are 2 agents. Each observes a state with length: 24\n",
      "The state for the first agent looks like: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.         -6.65278625 -1.5\n",
      " -0.          0.          6.83172083  6.         -0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents \n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Updating configuration \n",
    "Based on values found we can update our configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.num_agents = num_agents\n",
    "config.action_size = action_size\n",
    "config.state_size = state_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training the agents\n",
    "\n",
    "### 4.1 . Algorithm\n",
    "To solve this problem, the Deep Deterministic Policy Gradient will be used. DDPG adapts the ideas of Deep Q-Learning to the continuous action domain. The actor network approximates the optimal policy deterministically (best believed action). The critic evaluates the optimal action value function using the best believed action given by the actor network. DDPG also uses a repÄºay buffer where experience tuples are stored.\n",
    "\n",
    "From [Continuous control with deep reinforcement learning](https://arxiv.org/abs/1509.02971v5) we can find a description of the algorithm:\n",
    "\n",
    "\n",
    "<img src=\"./doc/ddpg.png\" alt=\"Drawing\" width=\"700\"/>\n",
    "\n",
    "### 4.2 . Network and Parameters \n",
    "Here both the critic newtork and the actor network have two hidden layers with 512 and 256 nodes respectively.\n",
    "\n",
    "Actor network maps states to actions: \n",
    "\n",
    "<img src=\"./doc/actor.png\" alt=\"Drawing\" width=\"700\"/>\n",
    "\n",
    "The critic network maps (state, action) pairs to Q values: \n",
    "\n",
    "<img src=\"./doc/critic.png\" alt=\"Drawing\" width=\"700\"/>\n",
    "\n",
    "\n",
    "The parameters used were:\n",
    "    \n",
    "| Parameter Description|  Variable  | Value |\n",
    "|-----------|------------|------|\n",
    "|Size of the replay buffer D|BUFFER_SIZE|1e6|\n",
    "|Mini-batch size|BATCH_SIZE|512|\n",
    "|Discount factor|GAMMA|0.99|\n",
    "|$\\\\tau$ for soft update of target parameters|TAU|1e-3|\n",
    "|Actor learning rate|LR|3e-4|\n",
    "|Actor learning rate|LR|5e-4|\n",
    "|L2 weight decay|WEIGHT_DECAY|0.0|\n",
    "\n",
    "When training the environment, we need to set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent import Agent\n",
    "from replay import ReplayBuffer \n",
    "import torch\n",
    "\n",
    "agents = [Agent(config) for _ in range(config.num_agents)]\n",
    "memory = ReplayBuffer(config.action_size, config.buffer_size, config.batch_size, config.random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ddpg(n_episodes=3000, max_steps=2000, shared=True):\n",
    "    scores_global = []\n",
    "    moving_scores = deque(maxlen=100)\n",
    "    timestep = 0\n",
    "    \n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        \n",
    "        ## Reset all agents\n",
    "        for agent in agents:\n",
    "            agent.reset()\n",
    "            \n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        states = env_info.vector_observations           \n",
    "        scores = np.zeros(num_agents)\n",
    "\n",
    "        for i in range(max_steps):\n",
    "            # Each agent takes its action\n",
    "            actions = [agent.act(np.expand_dims(state, axis=0))\n",
    "               for agent, state in zip(agents, states)]\n",
    "            \n",
    "            # Retrieving information from interaction with environment\n",
    "            env_info = env.step(actions)[brain_name]\n",
    "            rewards = env_info.rewards\n",
    "            next_states = env_info.vector_observations\n",
    "            dones = env_info.local_done\n",
    "\n",
    "            # Adding experience tuples to the shared buffer\n",
    "            for state, action, reward, next_state, done in zip(states, actions, rewards, next_states, dones):\n",
    "                memory.add(state, action, reward, next_state, done)\n",
    "\n",
    "            # Learn every update_every time steps.\n",
    "            timestep = (timestep + 1) % config.update_every\n",
    "            if timestep == 0:\n",
    "              # If enough samples are available in memory, get random subset and learn\n",
    "              if len(memory) > config.batch_size:\n",
    "                for agent in agents:\n",
    "                    if shared:\n",
    "                        experiences = memory.sample()\n",
    "                    else:\n",
    "                        experiences = agent.memory.sample()\n",
    "                    agent.learn(experiences, config.gamma)\n",
    "\n",
    "            scores += rewards\n",
    "            states = next_states\n",
    "                \n",
    "        current_average_score = np.mean(scores)\n",
    "        moving_scores.append(current_average_score)\n",
    "        scores_global.append(current_average_score)\n",
    "        \n",
    "        print('\\rEpisode {} \\t Current average: {:.4f}  \\tAverage Score: {:.4f}' \\\n",
    "              .format(i_episode, current_average_score, np.mean(moving_scores)), end=\"\")\n",
    "        \n",
    "        if i_episode % 10 == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(moving_scores)))\n",
    "        if np.mean(moving_scores)>=0.5:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode, np.mean(moving_scores)))\n",
    "            torch.save(agents[0].actor_local.state_dict(), './data/checkpoint_actor.pth')\n",
    "            torch.save(agents[0].critic_local.state_dict(), './data/checkpoint_critic.pth')\n",
    "            break \n",
    "            \n",
    "    return scores_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lgos/anaconda3/envs/drlnd/lib/python3.6/site-packages/torch/nn/functional.py:995: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 10\tAverage Score: -0.62\n",
      "Episode 20\tAverage Score: -0.65\n",
      "Episode 30\tAverage Score: -0.31\n",
      "Episode 40\tAverage Score: 0.13\n",
      "Episode 47 \t Current average: 3.1450  \tAverage Score: 0.5518\n",
      "Environment solved in 47 episodes!\tAverage Score: 0.55\n"
     ]
    }
   ],
   "source": [
    "scores = ddpg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, we can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Ideas for future work\n",
    "To improve the agents performance some possible options are:\n",
    "- Test algorithms like PPO, A3C or D4PG \n",
    "- Changing network architecture, hyperparameters or size.\n",
    "- Grid search to find optimal hyperparameters\n",
    "- Test individual replay buffer for each agent"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
